<!DOCTYPE HTML>

<html>
	<head>
		<title>A/B Testing</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Header -->
			<header id="header">
				<div class="inner">
					<a class="image avatar"><img src="images/avatars/pic10.jpg" alt="avatar" /></a>
					<h1><strong>Johanna Schmidle</strong> <br />
					Owns a ton of <br /> beaded jewelry
					</h1>
				</div>
			</header>

		<!-- Main -->
			<div id="main">

				<!-- One -->
				<section id="one">
					<header class="major">
						<h2>A/B Testing for E-Commerce Fashion Brand</h2>
						<h3>Gems of Insight: Optimizing Ads for ChicBeads</h3>
						<p>Link to project repository on <a href="https://github.com/johannaschmidle/ABTesting-FashionCampaign/tree/main">GitHub</a> </p>
					</header>

                    <h2>Project Background</h2>
                    ChicBeads, the sisterstore to a popular clothing store, is a company in the E-commerce fashion industry that sells beaded bracelets for $5.00 (USD) via an online platform. <br />
                    <br />
                    This project analyzes and sythesizes data to uncover insights into the effectiveness of the companys new marketing campaign compared to its traditional one. <br />
                    <ul>
                        <li><strong>Control Campaign:</strong> The control campaign focused on traditional display ads featuring static images of their latest clothing collection.</li>
                        <li><strong>Test Campaign:</strong> The test campaign experimented with video ads showcasing short fashion shows and styling tips from influencers.</li>
                    </ul>
                    Insights and recommendations are provided in the following key areas:
                    <ul>
                        <li><b>No. of Purchases:</b> determine if there is a significant difference in the number of purchases between different campaigns.</li>
                        <li><b>Engagement & Conversion:</b> analyze Website Clicks and Add to Cart actions to determine which campaign better engages and converts users.</li>
                        <li><b>Cost Efficiency:</b> compare ROI and Conversion Rates to see which strategy provides greater value for investment.</li>
                        <li><b>Audience Reach:</b> evaluate the effectiveness of each campaign in reaching and engaging the target audience.
                        </li>
                    </ul>
                    
                        An interactive Tableau dashboard can be found <a href="https://public.tableau.com/app/profile/johanna.schmidle/viz/ChicBeadsAB-TestingDashboard/Dashboard2" target="_blank"> here</a>
                        <br />
                        The Python code used to clean, organize and prepare data can be found at the top of this <a href="https://github.com/johannaschmidle/ABTesting-FashionCampaign/blob/main/ab-testing-project.ipynb" target="_blank"> Python notebook</a> 
                        <br />
                        The Python code used to visualize and explore the data can be found in the same <a href="https://github.com/johannaschmidle/ABTesting-FashionCampaign/blob/main/ab-testing-project.ipynb" target="_blank"> Python notebook</a> 
                        <br />
                        The Python code used to perform statistical tests can be found in the same <a href="https://github.com/johannaschmidle/ABTesting-FashionCampaign/blob/main/ab-testing-project.ipynb" target="_blank"> Python notebook</a> 
                    </section>

                <!-- five -->
				<section id="five">
                    <h2>Data Structure</h2>
                    The main database for the analysis consists two tables: TestCampaign and ControlCampaign. They hold the same sales information for each respective campaign. <br />
                    <br />
                    <img src="images/fulls/ERDChicBeads.png" alt="Chic Beads ERD" width="700"> <br />
                    <br />
                    The database can be accessed here:<a href="https://www.kaggle.com/datasets/amirmotefaker/ab-testing-dataset" target="_blank"> https://www.kaggle.com/datasets/amirmotefaker/ab-testing-dataset</a> <br />
                    
				</section>


                <!-- Two -->
				<section id="two">
                    <h2>Executive Summary</h2>
                    Below is the overview section of the interactive dashboard and there are more examples from this and the Python notebook throughout the report. The Tableau dashboaard can be found <a href="https://public.tableau.com/app/profile/johanna.schmidle/viz/ChicBeadsAB-TestingDashboard/Dashboard2" target="_blank"> here</a> and the Python notebook can be found <a href="https://github.com/johannaschmidle/ABTesting-FashionCampaign/blob/main/ab-testing-project.ipynb" target="_blank"> here</a>. <br/>
                    <br/>
                    <img src="images/fulls/ChicOverview.png" alt="Chic Beads" width="700"> 
                    <br/>
                    <br />
                    <b>Number of Purchases</b>
                    <ul>
                        <li>
                            There is no statistically significant difference in the number of purchases between the Control and Test Campaigns. Despite the Test Campaignâ€™s engaging format, it did not lead to higher purchase rates compared to the static ads in the Control Campaign.
                        </li>
                        <br />
                        <img src="images/fulls/ChicPurchases.png" alt="Chic Beads" width="500"> 
                    </ul>
                    <b>Engagement & Conversion:</b>
                    <ul>
                        <li>The Test Campaign had a significantly higher Click-Through Rate (CTR) and more Add to Cart actions, indicating better engagement and a stronger conversion funnel. However, it did not lead to a statistically significant increase in purchase rates.</li>
                    </ul>
                    <b>Cost Efficiency</b>
                    <ul>
                        <li>Despite fewer purchases, the Control Campaign proved more cost-effective, achieving a higher Return on Investment (ROI) compared to the Test Campaign.</li>
                        <img src="images/fulls/ChicBeadsCost.png" alt="Cost" width="400"> <br />
                        <li><b>Test Campaign:</b> Notice that it looks like the more money that is spent on the Test Campaign typically resulted in more purchases for the same cost as the Control Campaign. Also, this campaign has the max purchases out of the two, but it also has the min.</li>
                        <li><b>Control Campaign:</b> Notice that it looks like the less money that is spent on the Control Campaign typically resulted in more purchases for the same cost as the test group.</li>
                    </ul>
                    <b>Audience Reach:</b>
                    <ul>
                        <li>The Control Campaign reached a broader audience, but this did not translate into higher conversions. The Test Campaign demonstrated a more focused impact, significantly increasing engagement metrics. </li>
                    </ul>

                    <h2>Detailed Summary of Findings</h2>

                    <h4>From Visualizations</h4>
                    <ul>
                        <li>The control campaign reaches a broader audience, but that does not result in more people adding to cart. The test campaign seems to be more focused, resulting in a stronger correlation between Add to Cart and Purchase.</li>
                        <li>The advertisement seems to match what customers are searching for (this is inferred from the strong correlation between views, website clicks, add to cart)</li>
                        <li>The Control Campaign is more cost-effective than the Test Campaign</li>
                        <li>The Test Campaign has the most sales</li>
                        <li>Recommended for the Test Campaign to spend more, and the Control Campaign to spend less.</li>
                    </ul>

                    <h4>Mann-Whitney U Test/ Two-Sample T-Test</h4>
                    <ul>
                        <li><strong>Purchase:</strong> The Test and Control campaigns have no significant difference in Purchase rates.</li>
                        <li><strong>WebsiteClicks:</strong> There is no significant difference in WebsiteClicks rates between Test and Control.</li>
                        <li><strong>Reach:</strong> The difference in Reach rates between the Test and Control is statistically significant.</li>
                        <li><strong>AddtoCart:</strong> The difference in AddtoCart rates between Test and Control is statistically significant.</li>
                    </ul>

                    <h4>Pairwise Tests</h4>
                    <ul>
                        <li><strong>Purchase:</strong> There is no meaningful difference in the Purchase rates between the Control and Test campaigns.</li>
                        <li><strong>WebsiteClicks:</strong> The Test campaign does not lead to a statistically significant difference in WebsiteClicks compared to the Control campaign.</li>
                        <li><strong>Reach:</strong> The Test campaign has a significantly higher impact on Reach compared to the Control campaign, with a large effect size. The evidence strongly supports the presence of a meaningful difference.</li>
                        <li><strong>AddtoCart:</strong> The Test campaign has a significantly different impact on AddtoCart compared to the Control campaign, with a large effect size.</li>
                    </ul>

                    <h4>Additional Performance Indicators</h4>
                    <ul>
                        <li><strong>Cost Per Acquisition (CPA):</strong> $4.67</li>
                        <li><strong>Return on Investment (ROI):</strong> The Control Campaign performed better.</li>
                        <li><strong>Conversion Rate:</strong> The Control Campaign performed better.</li>
                        <li><strong>Click Through Rate (CTR):</strong> The Test Campaign performed better.</li>
                        <li>The Test and Control campaigns have no significant difference in ROI rates.</li>
                        <li>There is no significant difference in Conversion Rate rates between the Test and Control campaigns.</li>
                        <li>There is a statistically significant difference in CTR rates between the Test and Control campaigns.</li>
                    </ul>

				</section>

                <!-- Four -->
				<section id="four">
                    <h2>Overall</h2>
                    <ul>
                        <li><strong>Control Campaign:</strong> Although the Control Campaign effectively reaches a broader audience, this does not result in higher Add to Cart or Purchase rates. The campaign is more cost-effective, indicated by a higher ROI and Conversion Rate.</li>
                        <li><strong>Test Campaign:</strong> The Test Campaign is more effective in converting viewers to customers, as seen in the strong correlation between Add to Cart and Purchase rates. The Test Campaign also has a higher CTR, indicating more engaged viewers.</li>
                        <li><strong>Reach and Add to Cart:</strong> Both metrics show statistically significant differences favoring the Test Campaign.</li>
                        <li><strong>Purchase and Website Clicks:</strong> No significant differences between campaigns.</li>
                        <li>The return on the advertisement spend is higher in the Control Campaign than the Test campaign.</li>
                    </ul>

                    <h2>Recommendations For Company</h2>
                    <ul>
                        <li><b>Allocate Budget:</b> Increase the advertising spend on the Test Campaign to capitalize on its higher engagement potential, while monitoring ROI.</li>
                        <li><b>Refine Content Strategy:</b> Continue using video ads and explore additional influencer-driven content to boost conversion rates.</li>
                        <li><b>Continuous Experimentation:</b> Maintain the current strategy but regularly run A/B tests to refine and optimize advertising effectiveness.</li>
                        <li><b>Targeted Advertising:</b> Focus on more targeted approaches, like those used in the Test Campaign, to improve conversion rates.</li>
                        <li><b>Ad Relevance:</b> Align ads with customer search behavior, leveraging the strong correlation between Searches and View Content.</li>
                      </ul>

                    <h2>Recommended Next Analysis Steps</h2>
                    <ul>
                        <li><strong>Regression Analysis:</strong> Construct a polynomial regression model to predict the number of Impressions, Website Clicks, and Purchases. This can be used to identify optimum levels of expenditure on the Control and Test campaign.</li>
                        <li><strong>Trend Analysis:</strong> Conduct a time series analysis to understand how campaign performance changes over time and identify any seasonal trends.</li>
                        <li><strong>Segmentation Analysis:</strong> Break down the results by demographic segments (e.g., age, gender, location) to understand which segments respond better to each campaign.</li>
                    </ul>

                    <b>Conclusion:</b> The Test Campaign shows promise for driving higher engagement, but ongoing testing and optimization are essential to balance cost efficiency and conversion outcomes.
				</section>

                <!-- Three -->
				<section id="three">
                    <h2>Project Structure</h2>
                    <b>This project has two parts:</b>
							<ul>
								<li>
									Part 1:<a href="https://github.com/johannaschmidle/ABTesting-FashionCampaign/blob/main/ab-testing-project.ipynb" target="_blank"> Python Notebook</a> 
                                    <ol>
                                            <li>Clean Data</li>
                                            <li>Visualize Data</li> 
                                            <li>Statistical Tests + Hypothesis Testing (Mann-Whitney U Test/ Two-Sample T-Test, Pairwise Tests)</li> 
                                    </ol>
								</li>
								<li>
									Part 2:<a href="https://public.tableau.com/app/profile/johanna.schmidle/viz/ChicBeadsAB-TestingDashboard/Dashboard2" target="_blank"> Interactive Dashboard</a>
									<img src="images/fulls/ABTestingDash.png" alt="Chic Beads Dashboard" width="700"> <br />
								</li>
							</ul>
				</section>
								
			</div>

		<!-- Footer -->
			<footer id="footer">
				<div class="inner">
					<a href="index.html">Back to Main Page</a>
					<ul class="icons">
						<li><a href="https://www.kaggle.com/johannaschmidle7" class="icon brands fa-kaggle" target="_blank"><span class="label">Kaggle</span></a></li>
						<li><a href="https://github.com/johannaschmidle" class="icon brands fa-github" target="_blank"><span class="label">Github</span></a></li>
						<li><a href="https://ca.linkedin.com/in/johannaschmidle" class="icon brands fa-linkedin" target="_blank"><span class="label">LinkedIn</span></a></li>
						<li><a href="mailto:johannaschmidle7@gmail.com" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
					</ul>
					<ul class="copyright">
						<li>&copy; Untitled</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>